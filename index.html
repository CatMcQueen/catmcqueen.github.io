<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"  
  "http://www.w3.org/TR/html4/loose.dtd">  
<html > 
<head><title>Use NLTK to Write Your Own Sherlock Novel</title> 
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1"> 
<meta name="generator" content="TeX4ht (http://www.tug.org/tex4ht/)"> 
<meta name="originator" content="TeX4ht (http://www.tug.org/tex4ht/)"> 
<!-- html --> 
<meta name="src" content="tutorial_lstm.tex"> 
<link rel="stylesheet" type="text/css" href="tutorial_lstm.css"> 
</head><body 
>
   <div class="maketitle">
                                                                  

                                                                  
                                                                  

                                                                  

<h2 class="titleHead">Use NLTK to Write Your Own Sherlock Novel</h2>
<div class="author" ><span 
class="ptmr7t-x-x-120">Cat McQueen</span></div><br />
<div class="date" ><span 
class="ptmr7t-x-x-120">May 2, 2021</span></div>
   </div>
   <h3 class="likesectionHead"><a 
 id="x1-1000"></a>Contents</h3>
   <div class="tableofcontents">
   <span class="sectionToc" >1 <a 
href="#x1-20001" id="QQ2-1-2">Get Started on Google Colab</a></span>
<br />   <span class="sectionToc" >2 <a 
href="#x1-30002" id="QQ2-1-4">Import data</a></span>
<br />   &#x00A0;<span class="subsectionToc" >2.1 <a 
href="#x1-40002.1" id="QQ2-1-5">Method 1 (Temporary Upload):</a></span>
<br />   &#x00A0;<span class="subsectionToc" >2.2 <a 
href="#x1-50002.2" id="QQ2-1-8">Method 2 Google Drive:</a></span>
<br />   &#x00A0;<span class="subsectionToc" >2.3 <a 
href="#x1-60002.3" id="QQ2-1-9">Method 3 (Recommended):</a></span>
<br />   <span class="sectionToc" >3 <a 
href="#x1-70003" id="QQ2-1-10">Read and Process File</a></span>
<br />   &#x00A0;<span class="subsectionToc" >3.1 <a 
href="#x1-80003.1" id="QQ2-1-11">1: Removing White Space and Punctuation</a></span>
<br />   &#x00A0;<span class="subsectionToc" >3.2 <a 
href="#x1-90003.2" id="QQ2-1-12">Remove all Leading White Space:</a></span>
<br />   &#x00A0;<span class="subsectionToc" >3.3 <a 
href="#x1-100003.3" id="QQ2-1-13">Remove all Formatting Spaces:</a></span>
<br />   &#x00A0;<span class="subsectionToc" >3.4 <a 
href="#x1-110003.4" id="QQ2-1-14">Remove all Punctuation:</a></span>
<br />   <span class="sectionToc" >4 <a 
href="#x1-120004" id="QQ2-1-15">Analyze Corpus</a></span>
<br />   &#x00A0;<span class="subsectionToc" >4.1 <a 
href="#x1-130004.1" id="QQ2-1-16">Identify Word Based Data:</a></span>
<br />   &#x00A0;<span class="subsectionToc" >4.2 <a 
href="#x1-140004.2" id="QQ2-1-17">Identify Sentence Based Data:</a></span>
<br />   <span class="sectionToc" >5 <a 
href="#x1-150005" id="QQ2-1-18">Encode Corpus</a></span>
<br />   &#x00A0;<span class="subsectionToc" >5.1 <a 
href="#x1-160005.1" id="QQ2-1-19">Data Preparation</a></span>
<br />   <span class="sectionToc" >6 <a 
href="#x1-170006" id="QQ2-1-20">Create and Run Model</a></span>
<br />   &#x00A0;<span class="subsectionToc" >6.1 <a 
href="#x1-180006.1" id="QQ2-1-21">Create Model</a></span>
<br />   &#x00A0;<span class="subsectionToc" >6.2 <a 
href="#x1-190006.2" id="QQ2-1-22">Writing Inline One-Hot Encoding</a></span>
<br />   &#x00A0;<span class="subsectionToc" >6.3 <a 
href="#x1-200006.3" id="QQ2-1-24">Speed Up Using Tensor GPU</a></span>
<br />   &#x00A0;<span class="subsectionToc" >6.4 <a 
href="#x1-210006.4" id="QQ2-1-26">Using Model Generate Text</a></span>
   </div>
                                                                  

                                                                  
<!--l. 30--><p class="noindent" >
   <h3 class="sectionHead"><span class="titlemark">1    </span> <a 
 id="x1-20001"></a>Get Started on Google Colab</h3>
<!--l. 32--><p class="noindent" >Google Colab is an environment that allows you to do Machine and Deep Learning for free. It
can be connected to GitHub and has GPUs that you can use for free. It runs as a Jupyter
notebook.
<!--l. 34--><p class="indent" >   Google Colab is found at https://colab.research.google.com and requires a gmail account.
Sign into your gmail account and it will open a pop-up. In the bottom right corner, select
&#8221;NEW NOTEBOOK&#8221;.
<!--l. 37--><p class="indent" >   The window should appear the same as Figure&#x00A0;<a 
href="#x1-2001r1">1<!--tex4ht:ref: fig:home --></a>
<!--l. 39--><p class="indent" >   <hr class="figure"><div class="figure" 
>
                                                                  

                                                                  
<a 
 id="x1-2001r1"></a>
                                                                  

                                                                  
<!--l. 41--><p class="noindent" ><img 
src="ColabHome.png" alt="PIC"  
>
<br /> <div class="caption" 
><span class="id">Figure&#x00A0;1: </span><span  
class="content">Colab Homepage</span></div><!--tex4ht:label?: x1-2001r1 -->
                                                                  

                                                                  
<!--l. 44--><p class="indent" >   </div><hr class="endfigure">
<!--l. 46--><p class="indent" >   Now that we&#8217;re on the right location, we can start coding!
   <h3 class="sectionHead"><span class="titlemark">2    </span> <a 
 id="x1-30002"></a>Import data</h3>
<!--l. 50--><p class="noindent" >The first thing we are going to do is import our Sherlock text file. Sherlock Holmes written by
Conan Doyle is now in the public domain and is a dataset we can use to train. This is
important to note: you cannot train networks for public consumption on texts that are
currently copyrighted.
<!--l. 52--><p class="noindent" >
   <h4 class="subsectionHead"><span class="titlemark">2.1    </span> <a 
 id="x1-40002.1"></a>Method 1 (Temporary Upload):</h4>
<!--l. 54--><p class="noindent" >To download for this session only (the session will time out after some period of inactivity on
the page).
<!--l. 56--><p class="indent" >   First, download the data onto your local system by downloading <a 
href="https://github.com/CatMcQueen/catmcqueen.github.io/blob/b67a282c9be6bfd1ed17796c2507b9108cffb6bc/sherlock.txt" >the Sherlock Text</a>. On
the webpage, on the right, there is a Download button that will allow you to download this
text.
<!--l. 59--><p class="indent" >   Then, we are going to import it into our local Colab you have started. On the side of your
colab noteboook, you will see a file icon (the fourth icon down on the left bar), if you click on
it you will see a folder location. In order to connect to the folder location, you need to be
connected to the runtime, which requires you run something. To get the file folder connected,
type
                                                                  

                                                                  
   <div class="verbatim" id="verbatim-1">
&#x00A0;&#x00A0;&#x00A0;&#x00A0;print('hello&#x00A0;world')
</div>
<!--l. 62--><p class="nopar" >Then while still inside the text box, press shift and Enter. This will run the code within the
box you are currently in.
<!--l. 65--><p class="indent" >   Repeat every new Run time: You will then see an empty folder path. We are going to
upload sherlock.txt to our setup so we can call it in our python script.
<!--l. 68--><p class="indent" >   <hr class="figure"><div class="figure" 
>
                                                                  

                                                                  
<a 
 id="x1-4001r2"></a>
                                                                  

                                                                  
<!--l. 70--><p class="noindent" ><img 
src="FileFolder.png" alt="PIC"  
>
<br /> <div class="caption" 
><span class="id">Figure&#x00A0;2: </span><span  
class="content">The File Upload Bar</span></div><!--tex4ht:label?: x1-4001r2 -->
                                                                  

                                                                  
<!--l. 73--><p class="indent" >   </div><hr class="endfigure">
<!--l. 75--><p class="indent" >   Click on the upload icon, and upload the sherlock.txt you previously downloaded to your
local system. Now we&#8217;re ready to read it in and parse the data.
<!--l. 77--><p class="indent" >   <hr class="figure"><div class="figure" 
>
                                                                  

                                                                  
<a 
 id="x1-4002r3"></a>
                                                                  

                                                                  
<!--l. 79--><p class="noindent" ><img 
src="GoogleDriveConnect.png" alt="PIC"  
>
<br /> <div class="caption" 
><span class="id">Figure&#x00A0;3: </span><span  
class="content">Select Connect to Google Drive</span></div><!--tex4ht:label?: x1-4002r3 -->
                                                                  

                                                                  
<!--l. 82--><p class="indent" >   </div><hr class="endfigure">
   <h4 class="subsectionHead"><span class="titlemark">2.2    </span> <a 
 id="x1-50002.2"></a>Method 2 Google Drive:</h4>
<!--l. 86--><p class="noindent" >First, download the data onto your local system by downloading <a 
href="https://github.com/CatMcQueen/catmcqueen.github.io/blob/b67a282c9be6bfd1ed17796c2507b9108cffb6bc/sherlock.txt" >the Sherlock Text</a>. On the
webpage, on the right, there is a Download button that will allow you to download this
text.
<!--l. 89--><p class="indent" >   To upload so the file can be read indefinitely, we&#8217;ll mount our google drive inline and
upload the file from there. First, click on the right Google Drive icon on the file
upload page shown in Figure&#x00A0;<a 
href="#x1-4001r2">2<!--tex4ht:ref: fig:filefolder --></a>. You will then see a window pop up asking you to
permit it to access your Drive. It may require you to register using an access code
the first time. When you see Figure&#x00A0;<a 
href="#x1-4002r3">3<!--tex4ht:ref: fig:connectdrive --></a> pop up, select Connect to Google Drive.
Run
                                                                  

                                                                  
   <div class="verbatim" id="verbatim-2">
&#x00A0;&#x00A0;&#x00A0;&#x00A0;%cd&#x00A0;drive/My&#x00A0;Drive/
</div>
<!--l. 93--><p class="nopar" >
<!--l. 95--><p class="indent" >   If you have saved sherlock.txt within another folder in Google Drive, append the folder
path to the path in the cd command. We will now be able to run our script even after the
runtime disconnects without loading sherlock.txt again.
<!--l. 97--><p class="noindent" >
   <h4 class="subsectionHead"><span class="titlemark">2.3    </span> <a 
 id="x1-60002.3"></a>Method 3 (Recommended):</h4>
<!--l. 99--><p class="noindent" >We are going to do a git checkout from this repository of just the sherlock.txt. This link
can be found by going to <a 
href="https://github.com/CatMcQueen/catmcqueen.github.io/blob/main/sherlock.txt" >the Sherlock Text</a> and copying the permalink from that
webpage.
                                                                  

                                                                  
   <div class="verbatim" id="verbatim-3">
&#x00A0;&#x00A0;&#x00A0;&#x00A0;!git&#x00A0;clone&#x00A0;-n&#x00A0;https://github.com/CatMcQueen/catmcqueen.github.io.git&#x00A0;--depth&#x00A0;1
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;%cd&#x00A0;catmcqueen.github.io
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;!git&#x00A0;checkout&#x00A0;HEAD&#x00A0;sherlock.txt
</div>
<!--l. 105--><p class="nopar" >
<!--l. 107--><p class="indent" >   This will checkout the file sherlock.txt from the repository, and allow us to call it in our
local system. Since it is part of our code, it will check it out every time we run
through the code; therefore, it does not require we reload data every runtime. It also
does not require you to ever download sherlock.txt to your own machine or Google
Drive.
<!--l. 109--><p class="noindent" >
   <h3 class="sectionHead"><span class="titlemark">3    </span> <a 
 id="x1-70003"></a>Read and Process File</h3>
<!--l. 111--><p class="noindent" >The first thing we are going to do is to read the text file in, and look at the data given. Now
that we have the sherlock.txt in our local runtime, read the file into a variable. Remember to
close the file after loading the data.
                                                                  

                                                                  
   <div class="verbatim" id="verbatim-4">
#&#x00A0;Open&#x00A0;a&#x00A0;file:&#x00A0;sherlock.txt&#x00A0;in&#x00A0;read&#x00A0;mode
&#x00A0;<br />file&#x00A0;=&#x00A0;open('sherlock.txt',mode='r')
&#x00A0;<br />
&#x00A0;<br />#&#x00A0;read&#x00A0;all&#x00A0;lines&#x00A0;into&#x00A0;sherlock_txt
&#x00A0;<br />sherlock_txt&#x00A0;=&#x00A0;file.read()
&#x00A0;<br />
&#x00A0;<br />#&#x00A0;close&#x00A0;the&#x00A0;file
&#x00A0;<br />file.close()
</div>
<!--l. 122--><p class="nopar" >
<!--l. 124--><p class="indent" >   Now that you have the file, we are going to process it. This entails 1) removing
punctuation and numbers, 2) removing any unnecessary white space, 3) reformatting into
sentences, instead of lines. Once the data is processed, we can tokenize it and begin to use the
data.
<!--l. 127--><p class="noindent" >
   <h4 class="subsectionHead"><span class="titlemark">3.1    </span> <a 
 id="x1-80003.1"></a>1: Removing White Space and Punctuation</h4>
<!--l. 129--><p class="noindent" >Since we read the file in from text, there is a chance there is both leading white space(at the
beginning of the file) and empty lines. We read the file in all at once, so we are going to
process the text as a whole.
<!--l. 131--><p class="noindent" >
   <h4 class="subsectionHead"><span class="titlemark">3.2    </span> <a 
 id="x1-90003.2"></a>Remove all Leading White Space:</h4>
<!--l. 133--><p class="noindent" >To remove the leading white space at the beginning of the file (we don&#8217;t want our first token
to be a space), we will run a regular expression to eliminate it.
                                                                  

                                                                  
   <div class="verbatim" id="verbatim-5">
&#x00A0;&#x00A0;&#x00A0;&#x00A0;import&#x00A0;re
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;sherlock_text1&#x00A0;&#x00A0;=&#x00A0;re.sub('^\s+',&#x00A0;'',&#x00A0;sherlock_txt)
</div>
<!--l. 137--><p class="nopar" >
<!--l. 139--><p class="indent" >   re allows us to do a substitution, with re(x, y) replacing anything matching the x pattern
with y. The carat in regular expressions represents a new line, and the s is all spaces, with the
+ meaning that there has to be at least 1 for it to match. This regular expression, then, is
replacing anything number of spaces at the beginning of the file with an empty vector. In
practice, this removes all leading space characters.
<!--l. 141--><p class="noindent" >
   <h4 class="subsectionHead"><span class="titlemark">3.3    </span> <a 
 id="x1-100003.3"></a>Remove all Formatting Spaces:</h4>
<!--l. 143--><p class="noindent" >Next we&#8217;ll remove all tabs, empty lines, and other forms of white space and replace them
with a single space. Since tokenizing often breaks on spaces, a single space between words is
the standard. In the same fashion as before, we&#8217;ll use re.sub.
                                                                  

                                                                  
   <div class="verbatim" id="verbatim-6">
&#x00A0;&#x00A0;&#x00A0;&#x00A0;sherlock_text2&#x00A0;=&#x00A0;re.sub(r'\s+',&#x00A0;'&#x00A0;',&#x00A0;sherlock_text1)
</div>
<!--l. 146--><p class="nopar" >In this case, r&#8217; means to not use the backslash as a literal character, but to use it as part of the
spaces.
                                                                  

                                                                  
   <div class="verbatim" id="verbatim-7">
&#x00A0;&#x00A0;&#x00A0;&#x00A0;'\s+'
&#x00A0;<br />&#x00A0;
</div>
<!--l. 150--><p class="nopar" >represents all whitespaces, so we are replacing all white spaces with a single space.
<!--l. 153--><p class="noindent" >
   <h4 class="subsectionHead"><span class="titlemark">3.4    </span> <a 
 id="x1-110003.4"></a>Remove all Punctuation:</h4>
<!--l. 155--><p class="noindent" >When we are generating text, we will not use this; however, for analyzing what words are
most used and learning the data, we will want to remove punctuation, as they are the most
common &#8221;words&#8221; in our corpus, and can be considered stopwords (words too common in text
to be valuable to know) in that sense.
                                                                  

                                                                  
   <div class="verbatim" id="verbatim-8">
&#x00A0;&#x00A0;&#x00A0;&#x00A0;sherlock_nopunc&#x00A0;=&#x00A0;re.sub('[^a-zA-Z&#x00A0;]',&#x00A0;'',&#x00A0;sherlock_text2)
&#x00A0;<br />&#x00A0;
</div>
<!--l. 158--><p class="nopar" >The carat in this set is a negator. Therefore, we are removing everything that is not also in the
brackets. [a-zA-Z] represents the set of all letters, lower and upper case. To make sure that we
are also retaining the spaces that we have inserted, there is also a space in the set. If we did
not include the space in this set, then all of the spaces would be removed from the text as
well.
<!--l. 161--><p class="noindent" >
   <h3 class="sectionHead"><span class="titlemark">4    </span> <a 
 id="x1-120004"></a>Analyze Corpus</h3>
<!--l. 164--><p class="noindent" >
   <h4 class="subsectionHead"><span class="titlemark">4.1    </span> <a 
 id="x1-130004.1"></a>Identify Word Based Data:</h4>
<!--l. 166--><p class="noindent" >To do this we want to use our filtered dataset, tokenize it, and then do some analysis on what
our max used data is. To tokenize our document, we will use the word tokenize function from
NLTK.
                                                                  

                                                                  
   <div class="verbatim" id="verbatim-9">
&#x00A0;&#x00A0;&#x00A0;&#x00A0;from&#x00A0;nltk.corpus&#x00A0;import&#x00A0;stopwords
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;from&#x00A0;nltk.tokenize&#x00A0;import&#x00A0;sent_tokenize,&#x00A0;word_tokenize
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;stopwords&#x00A0;=&#x00A0;set(stopwords.words('english'))
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;allwords&#x00A0;=&#x00A0;word_tokenize(sherlock_nopunc.lower())
&#x00A0;<br />&#x00A0;
</div>
<!--l. 172--><p class="nopar" >Once re have all of our words, we will want to remove all the stopwords (words that
are too common to be useful in learning about your dataset&#8211;think &#8217;the&#8217;, &#8217;a&#8217;, &#8217;and&#8217;,
etc).
                                                                  

                                                                  
   <div class="verbatim" id="verbatim-10">
&#x00A0;&#x00A0;&#x00A0;&#x00A0;clean_words&#x00A0;=&#x00A0;[k&#x00A0;for&#x00A0;k&#x00A0;in&#x00A0;allwords&#x00A0;if&#x00A0;k&#x00A0;not&#x00A0;in&#x00A0;stopwords]
&#x00A0;<br />&#x00A0;
</div>
<!--l. 176--><p class="nopar" >We here are taking only the words that are not in stopwords and putting them in a list. Now
we can analyze our list and get the most commonly used words. For right now, I only care
about the 20 most used words, so we are going to create a Counter (which creates a dictionary
of word, index pairs and gives context information about them. Counter has a function called
&#8221;most_common&#8221; that returns the dictionary item pairs of the x most commonly used
words.
                                                                  

                                                                  
   <div class="verbatim" id="verbatim-11">
&#x00A0;&#x00A0;&#x00A0;&#x00A0;from&#x00A0;collections&#x00A0;import&#x00A0;Counter
&#x00A0;<br />
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;def&#x00A0;most_frequent(inlist,&#x00A0;maxlist=10):
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;occurence_count&#x00A0;&#x00A0;&#x00A0;&#x00A0;=&#x00A0;Counter(inlist)
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;pairs&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;=&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;occurence_count.most_common(maxlist)#[0][0]
&#x00A0;<br />
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;most_common&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;=&#x00A0;[]
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;most_common_counts&#x00A0;=&#x00A0;[]
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;for&#x00A0;x&#x00A0;in&#x00A0;range(maxlist):
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;most_common.append(pairs[x][0])
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;most_common_counts.append(pairs[x][1])
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;return&#x00A0;most_common,&#x00A0;most_common_counts
&#x00A0;<br />
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;top_words,&#x00A0;word_counts&#x00A0;=&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;most_frequent(clean_words)
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;print(top_words)
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;print(word_counts)
</div>
<!--l. 196--><p class="nopar" >When you run this cell, you should see two lists. The first is printing out the most used words,
and the second is printing out the number of times each of those is used. The output of mine
is:
<!--l. 200--><p class="indent" >   [&#8217;said&#8217;, &#8217;holmes&#8217;, &#8217;upon&#8217;, &#8217;one&#8217;, &#8217;would&#8217;, &#8217;man&#8217;, &#8217;could&#8217;, &#8217;mr&#8217;, &#8217;us&#8217;, &#8217;well&#8217;]
<!--l. 202--><p class="indent" >   [2734, 2386, 2302, 2217, 1900, 1826, 1639, 1389, 1340, 1268]
<!--l. 204--><p class="indent" >   These are the top 10 used words in our document. Interestingly, if you don&#8217;t force it to be
lowercase on allwords, the output is
<!--l. 206--><p class="indent" >   [&#8217;I&#8217;, &#8217;said&#8217;, &#8217;Holmes&#8217;, &#8217;The&#8217;, &#8217;upon&#8217;, &#8217;It&#8217;, &#8217;He&#8217;, &#8217;one&#8217;, &#8217;would&#8217;, &#8217;man&#8217;]
<!--l. 208--><p class="indent" >   [14361, 2734, 2383, 2380, 2288, 2122, 2062, 2033, 1864, 1807]
<!--l. 210--><p class="indent" >   As you can see, the stopwords are only in the lowercase, so filtering the list without
converting it to lower removes the filtering on the uppercase versions of the stop
words.
<!--l. 212--><p class="indent" >   Unsurprisingly, without filtering for stopwords, the output is
<!--l. 214--><p class="indent" >   [&#8217;the&#8217;, &#8217;and&#8217;, &#8217;of&#8217;, &#8217;I&#8217;, &#8217;to&#8217;, &#8217;a&#8217;, &#8217;that&#8217;, &#8217;in&#8217;, &#8217;was&#8217;, &#8217;it&#8217;]
<!--l. 216--><p class="indent" >   [29401, 14791, 14600, 14361, 13672, 13002, 9324, 8971, 8381, 7008]
<!--l. 218--><p class="indent" >   Now you can see why filtering by stop words is useful in learning your data.
<!--l. 220--><p class="noindent" >
   <h4 class="subsectionHead"><span class="titlemark">4.2    </span> <a 
 id="x1-140004.2"></a>Identify Sentence Based Data:</h4>
<!--l. 222--><p class="noindent" >NLTK also has a sentence wise tokenizer, which breaks on common sentence tokens (&#8217;.&#8217;, &#8217;!&#8217;,
&#8217;?&#8217;, etc.) so let&#8217;s learn what the most common sentences are in our document.
                                                                  

                                                                  
   <div class="verbatim" id="verbatim-12">
&#x00A0;&#x00A0;&#x00A0;&#x00A0;sentences&#x00A0;=&#x00A0;sent_tokenize(sherlock_text1.lower())
</div>
<!--l. 226--><p class="nopar" >
<!--l. 228--><p class="indent" >   Similar to how we analyzed our word count, we will now analyze which sentences are the
most common.
                                                                  

                                                                  
   <div class="verbatim" id="verbatim-13">
&#x00A0;&#x00A0;&#x00A0;&#x00A0;from&#x00A0;collections&#x00A0;import&#x00A0;Counter
&#x00A0;<br />
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;def&#x00A0;most_frequent(inlist,&#x00A0;maxlist=10):
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;occurence_count&#x00A0;&#x00A0;&#x00A0;&#x00A0;=&#x00A0;Counter(inlist)
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;pairs&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;=&#x00A0;occurence_count.most_common(maxlist)
&#x00A0;<br />
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;most_common&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;=&#x00A0;[]
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;most_common_counts&#x00A0;=&#x00A0;[]
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;for&#x00A0;x&#x00A0;in&#x00A0;range(maxlist):
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;most_common.append(pairs[x][0])
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;most_common_counts.append(pairs[x][1])
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;return&#x00A0;most_common,&#x00A0;most_common_counts
&#x00A0;<br />
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;top_sent,&#x00A0;sent_counts&#x00A0;=&#x00A0;most_frequent(sentences,&#x00A0;maxlist=5)
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;print(top_sent)
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;print(sent_counts)
</div>
<!--l. 247--><p class="nopar" >
<!--l. 249--><p class="indent" >   running our sentence tokenizer, the output is
<!--l. 251--><p class="indent" >   [&#8217;i asked.&#8217;, &#8217;he asked.&#8217;, &#8217;he cried.&#8217;, &#8217;said he.&#8217;, &#8217;holmes?&#8221;&#8217;]
<!--l. 253--><p class="indent" >   [75, 59, 52, 48, 38]
<!--l. 255--><p class="indent" >   Meaning there were 75 sentences in our corpus that were &#8217;I asked.&#8217;
<!--l. 257--><p class="indent" >   Now that we know a little about our document, let&#8217;s train our model.
<!--l. 259--><p class="noindent" >
   <h3 class="sectionHead"><span class="titlemark">5    </span> <a 
 id="x1-150005"></a>Encode Corpus</h3>
<!--l. 261--><p class="noindent" >
   <h4 class="subsectionHead"><span class="titlemark">5.1    </span> <a 
 id="x1-160005.1"></a>Data Preparation</h4>
<!--l. 262--><p class="noindent" >For our data generation training, we don&#8217;t want to eliminate stopwords or punctuation.
Therefore, we will use sherlock_2 to train as we want there to be punctuation in our final
text.
<!--l. 264--><p class="indent" >   The first thing we&#8217;re going to do is reset allwords to be sherlock_2 and create a label
encoder object for it. In this case, we don&#8217;t want our label encoder to represent unique words
in the dictionary, it is going to be the map from one hot back to our corpus. Then we want to
train our encoder to make a one-hot version of the corpus. For more information
on how this encoding works, see <a 
href="https://machinelearningmastery.com/how-to-one-hot-encode-sequence-data-in-python/" >this link</a>. We will also verify that the encoder
works.
                                                                  

                                                                  
   <div class="verbatim" id="verbatim-14">
&#x00A0;&#x00A0;&#x00A0;&#x00A0;#&#x00A0;first&#x00A0;lets&#x00A0;make&#x00A0;our&#x00A0;sequences
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;from&#x00A0;sklearn.preprocessing&#x00A0;import&#x00A0;OneHotEncoder
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;from&#x00A0;sklearn.preprocessing&#x00A0;import&#x00A0;LabelEncoder
&#x00A0;<br />
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;#&#x00A0;set&#x00A0;it&#x00A0;up&#x00A0;so&#x00A0;we&#x00A0;can&#x00A0;encode&#x00A0;our&#x00A0;data
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;encoder&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;=&#x00A0;LabelEncoder()
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;values&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;=&#x00A0;np.array(allwords)
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;int_encoded&#x00A0;&#x00A0;=&#x00A0;encoder.fit_transform(values)
&#x00A0;<br />
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;#&#x00A0;force&#x00A0;it&#x00A0;to&#x00A0;be&#x00A0;sparse&#x00A0;until&#x00A0;we&#x00A0;need&#x00A0;it&#x00A0;to&#x00A0;be&#x00A0;dense&#x00A0;when
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;#we're&#x00A0;putting&#x00A0;data&#x00A0;into&#x00A0;the&#x00A0;model
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;ohot_encoder&#x00A0;=&#x00A0;OneHotEncoder()
&#x00A0;<br />
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;#len(int_encoded)&#x00A0;is&#x00A0;the&#x00A0;same&#x00A0;length&#x00A0;as&#x00A0;our&#x00A0;len(allwords)
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;int_encoded&#x00A0;&#x00A0;=&#x00A0;int_encoded.reshape(len(int_encoded),&#x00A0;1)
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;ohot_encoded&#x00A0;=&#x00A0;ohot_encoder.fit_transform(int_encoded)
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;#verify&#x00A0;it&#x00A0;works
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;idx&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;=&#x00A0;int_encoded[0]
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;inverted&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;=&#x00A0;encoder.inverse_transform([np.argmax(ohot_encoded[idx,&#x00A0;:])])
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;#&#x00A0;and&#x00A0;to&#x00A0;verify&#x00A0;it&#x00A0;works,&#x00A0;we'll&#x00A0;check&#x00A0;that&#x00A0;the&#x00A0;inverted&#x00A0;val&#x00A0;is
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;#&#x00A0;the&#x00A0;same&#x00A0;as&#x00A0;the&#x00A0;index&#x00A0;at&#x00A0;that&#x00A0;location
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;assert&#x00A0;allwords[idx[0]]&#x00A0;==&#x00A0;inverted[0]
&#x00A0;<br />&#x00A0;
</div>
<!--l. 290--><p class="nopar" >
<!--l. 292--><p class="indent" >   Now we have our new word list and dictionary, we are going to create a set of sequences.
Since Colab is RAM limited and the dataset is quite large, we are going to do a sequence of
series of words, using SEQ_LENGTH to determine how long the sequence is and STEP to
determine how far the steps are from each other.
<!--l. 294--><p class="indent" >   Now generate the sequences. We are using the dictionary listed out and tied to another
dictionary to map indexes of the dictionary to words.
                                                                  

                                                                  
   <div class="verbatim" id="verbatim-15">
&#x00A0;&#x00A0;&#x00A0;&#x00A0;SEQ_LENGTH&#x00A0;=&#x00A0;4
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;STEP&#x00A0;=&#x00A0;5
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;def&#x00A0;make_sequences(text,&#x00A0;seq,&#x00A0;step):
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;sequences&#x00A0;&#x00A0;=&#x00A0;[]
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;next_words&#x00A0;=&#x00A0;[]
&#x00A0;<br />
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;#&#x00A0;skip&#x00A0;every&#x00A0;so&#x00A0;step,&#x00A0;and&#x00A0;collect&#x00A0;tokens
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;for&#x00A0;i&#x00A0;in&#x00A0;range(0,&#x00A0;VOCAB_SIZE&#x00A0;-&#x00A0;seq,&#x00A0;step):
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;cur_words&#x00A0;=&#x00A0;text[i:&#x00A0;i&#x00A0;+&#x00A0;seq&#x00A0;-1]
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;sequence&#x00A0;=&#x00A0;[]
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;for&#x00A0;idx,&#x00A0;x&#x00A0;in&#x00A0;enumerate(cur_words):
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;one_hot&#x00A0;=&#x00A0;ohot_encoded[i&#x00A0;+&#x00A0;idx]
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;sequence.append(one_hot)
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;sequences.append(sequence)
&#x00A0;<br />
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;next_word&#x00A0;=&#x00A0;text[i&#x00A0;+&#x00A0;seq]
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;one_hot&#x00A0;=&#x00A0;ohot_encoded[i&#x00A0;+&#x00A0;seq]
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;next_words.append(one_hot)
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;return&#x00A0;sequences,&#x00A0;next_words
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;ohot_x,&#x00A0;ohot_y&#x00A0;=&#x00A0;make_sequences(allwords,&#x00A0;SEQ_LENGTH,&#x00A0;STEP)
&#x00A0;<br />
&#x00A0;<br />&#x00A0;&#x00A0;
</div>
<!--l. 318--><p class="nopar" >
<!--l. 320--><p class="indent" >   As you can see, we are using the generated one-hot encoded indexes; however, we are
storing them in a sparse matrix because Google Colab is RAM limited. So for our
vocabulary, we are collecting each set of 4 words&#8211; 3 as our &#8221;current&#8221; words, and 1 as our
&#8221;next&#8221; word. Our current words will become our test input, and our next word will
become the training label the network is trying to learn. We are storing these in
lists, but we will convert them to arrays when we turn them into dense one-hot
matrices.
<!--l. 322--><p class="noindent" >
   <h3 class="sectionHead"><span class="titlemark">6    </span> <a 
 id="x1-170006"></a>Create and Run Model</h3>
<!--l. 324--><p class="noindent" >
   <h4 class="subsectionHead"><span class="titlemark">6.1    </span> <a 
 id="x1-180006.1"></a>Create Model</h4>
<!--l. 325--><p class="noindent" >We are going to use the Nadam optimizer, and the lr is a tunable parameter. Take time to
experiment with the learning rate to see what changes. We are doing a variable model that can
                                                                  

                                                                  
have extra LSTM layers in it. The LAYER_NUM variable allows you to change this number.
HIDDEN_DIM is the learnable dimensions, and is also tunable. Since we are on Google
Colab, that is restricted because of RAM size, but for models not learning, you can increase
or decrease this number.
                                                                  

                                                                  
   <div class="verbatim" id="verbatim-16">
&#x00A0;&#x00A0;&#x00A0;&#x00A0;#set&#x00A0;our&#x00A0;model&#x00A0;training&#x00A0;values
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;BATCH_SIZE&#x00A0;=&#x00A0;1
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;HIDDEN_DIM&#x00A0;=&#x00A0;50&#x00A0;#&#x00A0;may&#x00A0;need&#x00A0;to&#x00A0;tune&#x00A0;this.&#x00A0;Check&#x00A0;later
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;EPOCHS&#x00A0;=&#x00A0;30
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;optimizer&#x00A0;=&#x00A0;optimizers.Nadam(lr=.001)
&#x00A0;<br />
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;def&#x00A0;create_model():
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;input_len&#x00A0;=&#x00A0;SEQ_LENGTH
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;model&#x00A0;=&#x00A0;Sequential()
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;#since&#x00A0;we&#x00A0;know&#x00A0;the&#x00A0;input&#x00A0;size,&#x00A0;we&#x00A0;can&#x00A0;hard&#x00A0;code&#x00A0;this&#x00A0;input&#x00A0;shape
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;model.add(LSTM(HIDDEN_DIM,&#x00A0;input_shape=(SEQ_LENGTH,&#x00A0;VOCAB_SIZE)))
&#x00A0;<br />
&#x00A0;<br />
&#x00A0;<br />
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;#&#x00A0;Add&#x00A0;Output&#x00A0;Layer
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;model.add(Dense(VOCAB_SIZE))
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;model.add(Activation('softmax'))
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;model.compile(loss='categorical_crossentropy',&#x00A0;optimizer=optimizer,&#x00A0;metrics=['mean_absolute_error',&#x00A0;"accuracy"])
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;return&#x00A0;model
&#x00A0;<br />
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;model&#x00A0;=&#x00A0;create_model()
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;#&#x00A0;use&#x00A0;model.summary()&#x00A0;to&#x00A0;see&#x00A0;the&#x00A0;layers&#x00A0;and&#x00A0;their&#x00A0;respective&#x00A0;sizes
</div>
<!--l. 350--><p class="nopar" >
<!--l. 352--><p class="indent" >   Note that here we are monitoring the categorical cross entropy loss and monitoring the
total error and the accuracy. This allows us to see how accurate the model is becoming
during training, and gives a metric that is more human understandable than loss
values.
<!--l. 355--><p class="noindent" >
   <h4 class="subsectionHead"><span class="titlemark">6.2    </span> <a 
 id="x1-190006.2"></a>Writing Inline One-Hot Encoding</h4>
<!--l. 357--><p class="noindent" >To do this, we need to replace the data keras generator to supply a new batch every
time with the one-hot batch. This way we don&#8217;t overwhelm the Colab notebook.
Based on <a 
href="https://github.com/keras-team/keras/issues/9707" >this Keras help page</a> we can get the format and necessary elements of the
Generator.
                                                                  

                                                                  
   <div class="verbatim" id="verbatim-17">
&#x00A0;&#x00A0;&#x00A0;&#x00A0;##&#x00A0;Keras&#x00A0;has&#x00A0;a&#x00A0;native&#x00A0;shuffler,&#x00A0;but&#x00A0;since&#x00A0;our&#x00A0;output&#x00A0;isn't&#x00A0;one&#x00A0;hot,&#x00A0;we&#x00A0;need
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;##&#x00A0;to&#x00A0;shuffle&#x00A0;the&#x00A0;data&#x00A0;to&#x00A0;ensure&#x00A0;it&#x00A0;does&#x00A0;get&#x00A0;shuffled.
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;class&#x00A0;Generator(Sequence):
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;#&#x00A0;Class&#x00A0;is&#x00A0;a&#x00A0;dataset&#x00A0;wrapper&#x00A0;for&#x00A0;better&#x00A0;training&#x00A0;performance
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;def&#x00A0;__init__(self,&#x00A0;x_set,&#x00A0;y_set,&#x00A0;vocab_size,&#x00A0;batch_size=128):
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;self.x,&#x00A0;self.y&#x00A0;=&#x00A0;x_set,&#x00A0;y_set
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;self.batch_size&#x00A0;=&#x00A0;batch_size
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;self.indices&#x00A0;=&#x00A0;np.arange(self.x.shape[0])&#x00A0;#&#x00A0;all&#x00A0;possible&#x00A0;sequences
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;self.vocab_size&#x00A0;=&#x00A0;vocab_size
&#x00A0;<br />
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;def&#x00A0;__len__(self):
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;return&#x00A0;math.ceil(self.x.shape[0]&#x00A0;/&#x00A0;self.batch_size)
&#x00A0;<br />
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;def&#x00A0;__getitem__(self,&#x00A0;idx):
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;inds&#x00A0;=&#x00A0;self.indices[idx&#x00A0;&#x22C6;&#x00A0;self.batch_size:(idx&#x00A0;+&#x00A0;1)&#x00A0;&#x22C6;&#x00A0;self.batch_size]
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;indexed_x&#x00A0;=&#x00A0;self.x[inds]&#x00A0;#&#x00A0;sequences
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;indexed_y&#x00A0;=&#x00A0;self.y[inds]&#x00A0;#&#x00A0;next_words
&#x00A0;<br />
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;#&#x00A0;we&#x00A0;need&#x00A0;to&#x00A0;do&#x00A0;batching,&#x00A0;so&#x00A0;use&#x00A0;bool&#x00A0;to&#x00A0;save&#x00A0;space&#x00A0;(we&#x00A0;don't&#x00A0;need&#x00A0;an&#x00A0;int)
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;#&#x00A0;it's&#x00A0;one&#x00A0;hot&#x00A0;encoding&#x00A0;so&#x00A0;bool&#x00A0;works&#x00A0;fine
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;#&#x00A0;x&#x00A0;=&#x00A0;&#x00A0;[batch,&#x00A0;seq_length,&#x00A0;vocab_size]
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;#&#x00A0;y&#x00A0;=&#x00A0;[batch,&#x00A0;vocab_size]
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;#&#x00A0;for&#x00A0;y&#x00A0;it's&#x00A0;just&#x00A0;an&#x00A0;array&#x00A0;of&#x00A0;sparse&#x00A0;matricies,&#x00A0;so&#x00A0;just&#x00A0;convert&#x00A0;it
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;batch_y&#x00A0;=&#x00A0;np.asarray(indexed_y[0].todense())
&#x00A0;<br />
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;#&#x00A0;for&#x00A0;x,&#x00A0;it's&#x00A0;a&#x00A0;little&#x00A0;harder,&#x00A0;since&#x00A0;it's&#x00A0;an&#x00A0;array&#x00A0;of&#x00A0;3&#x00A0;dense&#x00A0;matricies
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;#&#x00A0;first&#x00A0;convert&#x00A0;it&#x00A0;to&#x00A0;a&#x00A0;list,&#x00A0;then&#x00A0;convert&#x00A0;it&#x00A0;to&#x00A0;a&#x00A0;dense&#x00A0;matrix,&#x00A0;then
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;#&#x00A0;convert&#x00A0;it&#x00A0;back&#x00A0;into&#x00A0;numpy&#x00A0;array
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;batch_x&#x00A0;=&#x00A0;[]
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;for&#x00A0;batchidx,&#x00A0;bat&#x00A0;in&#x00A0;enumerate(indexed_x):&#x00A0;#&#x00A0;for&#x00A0;every&#x00A0;seq&#x00A0;in&#x00A0;the&#x00A0;batch
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;batch_x.append(bat[0].todense())
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;batch_x&#x00A0;=&#x00A0;np.array(batch_x)
&#x00A0;<br />
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;return&#x00A0;batch_x,&#x00A0;batch_y
&#x00A0;<br />
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;return&#x00A0;batch_x,&#x00A0;batch_y
&#x00A0;<br />
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;def&#x00A0;on_epoch_end(self):
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;np.random.shuffle(self.indices)
&#x00A0;<br />
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;train_generator&#x00A0;=&#x00A0;Generator(np.array(ohot_x),&#x00A0;np.array(ohot_y),&#x00A0;VOCAB_SIZE,&#x00A0;batch_size=BATCH_SIZE)
</div>
<!--l. 401--><p class="nopar" >
                                                                  

                                                                  
<!--l. 403--><p class="indent" >   Essentially the only change we made to the original, is that we are forcing our x and y
arrays into dense matricies. In the __getitem__ function. Keras naturally shuffles the dataset
each epoch, so we are indexing into that item, and converting the one hot vectors
for input and output to be a dense version. For the input vector, that is a [batch,
seq_length, vocab_size] sized array, and for the label vector that is [batch, vocab_size] in
size.
<!--l. 405--><p class="indent" >   Now that our data is ready to put into the model, let&#8217;s call it by calling the generator class
and putting that as the input to the model.
                                                                  

                                                                  
   <div class="verbatim" id="verbatim-18">
&#x00A0;&#x00A0;&#x00A0;&#x00A0;model.fit(train_generator,&#x00A0;epochs=EPOCHS,&#x00A0;verbose=1,&#x00A0;batch_size=BATCH_SIZE)
</div>
<!--l. 409--><p class="nopar" >
<!--l. 411--><p class="indent" >   <hr class="figure"><div class="figure" 
>
                                                                  

                                                                  
<a 
 id="x1-19001r4"></a>
                                                                  

                                                                  
<!--l. 413--><p class="noindent" ><img 
src="TrainingOutput.png" alt="PIC"  
>
<br /> <div class="caption" 
><span class="id">Figure&#x00A0;4: </span><span  
class="content">Training Output From Model</span></div><!--tex4ht:label?: x1-19001r4 -->
                                                                  

                                                                  
<!--l. 416--><p class="indent" >   </div><hr class="endfigure">
<!--l. 418--><p class="indent" >   When we do that, you&#8217;ll see outputs on the bottom of that Colab text box, they should
look like Figure&#x00A0;<span 
class="ptmb7t-">??</span>. This will allow you to monitor the progress of your training to verify
that it is increasing in accuracy and decreasing in loss.
<!--l. 420--><p class="indent" >   If that&#8217;s going really slow for you (likely). We can add a GPU to speed up the model.fit
process.
   <h4 class="subsectionHead"><span class="titlemark">6.3    </span> <a 
 id="x1-200006.3"></a>Speed Up Using Tensor GPU</h4>
<!--l. 424--><p class="noindent" >To use the GPU to train (this will save you so much time), attach a GPU to your Colab. To do
this go to the Edit bar, and select Notebook Settings. From here you&#8217;ll select GPU to run your
network. TPUs require a lot of extra code to run, so make sure you select GPU, not
TPU.
<!--l. 426--><p class="indent" >   <hr class="figure"><div class="figure" 
>
                                                                  

                                                                  
<a 
 id="x1-20001r5"></a>
                                                                  

                                                                  
<!--l. 428--><p class="noindent" ><img 
src="GPUAccel.png" alt="PIC"  
>
<br /> <div class="caption" 
><span class="id">Figure&#x00A0;5: </span><span  
class="content">Use GPU to Accelerate Training</span></div><!--tex4ht:label?: x1-20001r5 -->
                                                                  

                                                                  
<!--l. 431--><p class="indent" >   </div><hr class="endfigure">
<!--l. 433--><p class="indent" >   Since GPU is already enabled in Tensorflow 2.0 (the default Tensorflow Google Colab
sources) you can run this like you would with a CPU. It does not require any changes to the
code.
   <h4 class="subsectionHead"><span class="titlemark">6.4    </span> <a 
 id="x1-210006.4"></a>Using Model Generate Text</h4>
<!--l. 437--><p class="noindent" >We have a trained model, now we can generate text from it. To do this we want more than just
one output word, so we are going to generate words in a function, and we are going to
generate GENERATE_LENGTH number of words. We&#8217;re going to pick a randomly
generated integer to get a word to start, then we are going to use the same random number to
create a one-hot array, so the input matches the expected. Since we are only doing this on one
index at a time, the space isn&#8217;t an issue, so we can immediately force them to dense
matrices. Doing that matches the expected input. From there, we will append the words
into a list, and then join them together to make a sentence. We are using .join(&#8217; &#8217;)
to force it to add a space between each word returned from the list so it makes a
sentence.
                                                                  

                                                                  
   <div class="verbatim" id="verbatim-19">
&#x00A0;&#x00A0;&#x00A0;&#x00A0;#&#x00A0;method&#x00A0;for&#x00A0;generating&#x00A0;text
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;GENERATE_LENGTH&#x00A0;=&#x00A0;20
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;def&#x00A0;generate_text(model,&#x00A0;length,&#x00A0;text_size):
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;#&#x00A0;first&#x00A0;get&#x00A0;a&#x00A0;random&#x00A0;word&#x00A0;as&#x00A0;our&#x00A0;starting&#x00A0;point&#x00A0;(input)
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;ix&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;=&#x00A0;[np.random.randint(text_size-SEQ_LENGTH)&#x00A0;+&#x00A0;SEQ_LENGTH]
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;val&#x00A0;&#x00A0;&#x00A0;&#x00A0;=&#x00A0;[np.argmax(ohot_encoded[idx,&#x00A0;:])]
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;y_char&#x00A0;=&#x00A0;np.ndarray.tolist(encoder.inverse_transform(val))
&#x00A0;<br />
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;#&#x00A0;this&#x00A0;is&#x00A0;the&#x00A0;output&#x00A0;text,&#x00A0;it'll&#x00A0;be&#x00A0;length&#x00A0;long
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;for&#x00A0;i&#x00A0;in&#x00A0;range(length):
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;#try:
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;#&#x00A0;one&#x00A0;hot&#x00A0;encode&#x00A0;the&#x00A0;current&#x00A0;word
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;X_words&#x00A0;=&#x00A0;[]
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;for&#x00A0;n&#x00A0;in&#x00A0;range(SEQ_LENGTH):
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;indexer&#x00A0;=&#x00A0;ix[0]&#x00A0;-&#x00A0;SEQ_LENGTH&#x00A0;+&#x00A0;n
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;X&#x00A0;=&#x00A0;ohot_encoded[indexer,&#x00A0;:]
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;X&#x00A0;=&#x00A0;X.todense()
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;X_words.append(X)
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;X_words&#x00A0;=&#x00A0;np.array(X_words)
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;#then&#x00A0;the&#x00A0;index&#x00A0;changes&#x00A0;to&#x00A0;the&#x00A0;predicted&#x00A0;word&#x00A0;and&#x00A0;we&#x00A0;continue
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;ix&#x00A0;=&#x00A0;[np.argmax(model.predict(X_words,&#x00A0;1))]
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;val&#x00A0;=&#x00A0;[np.argmax(ohot_encoded[ix,&#x00A0;:])]
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;y_char.append(np.ndarray.tolist(encoder.inverse_transform(val))[0])
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;#except:
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;#&#x00A0;&#x00A0;&#x00A0;&#x00A0;continue
&#x00A0;<br />
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;#&#x00A0;then&#x00A0;combine&#x00A0;all&#x00A0;the&#x00A0;words&#x00A0;into&#x00A0;a&#x00A0;sentence
&#x00A0;<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;return&#x00A0;('&#x00A0;').join(y_char)
&#x00A0;<br />
&#x00A0;<br />generate_text(model,&#x00A0;GENERATE_LENGTH,&#x00A0;len(allwords))
&#x00A0;<br />&#x00A0;
</div>
<!--l. 471--><p class="nopar" >
<!--l. 473--><p class="indent" >   This should write out generated text. Here is the example output text that mine
gave:
                                                                  

                                                                  
   <div class="verbatim" id="verbatim-20">
&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;must&#x00A0;he&#x00A0;mixed&#x00A0;gregson&#x00A0;pass&#x00A0;to&#x00A0;here&#x00A0;said&#x00A0;and&#x00A0;her&#x00A0;i&#x00A0;of&#x00A0;in&#x00A0;and&#x00A0;still&#x00A0;redskins&#x00A0;horsemen&#x00A0;falling&#x00A0;to&#x00A0;for&#x00A0;refer
&#x00A0;<br />&#x00A0;
</div>
<!--l. 477--><p class="nopar" >
<!--l. 479--><p class="indent" >   Congratulations! You have now generated a document!
    
</body></html> 

                                                                  


